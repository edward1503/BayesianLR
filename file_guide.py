# -*- coding: utf-8 -*-
"""File guide

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/136px56zpdFZ908qZ8znJYQswKbnFRXhw
"""

!pip install -q \
    "numpy==2.0.2" \
    "pandas==2.2.2" \
    "scipy==1.13.1" \
    "scikit-learn==1.5.2" \
    "statsmodels==0.14.2" \
    "matplotlib" \
    "pymc" \
    "arviz"

import numpy as np, pandas as pd, matplotlib, scipy, statsmodels, sklearn
import pymc as pm, arviz as az

print("numpy       :", np.__version__)
print("pandas      :", pd.__version__)
print("scipy       :", scipy.__version__)
print("sklearn     :", sklearn.__version__)
print("statsmodels :", statsmodels.__version__)
print("pymc        :", pm.__version__)
print("arviz       :", az.__version__)

from google.colab import files

print("üìÇ Ch·ªçn file CSV ƒë·ªÉ upload...")
uploaded = files.upload()

# L·∫•y t√™n file ƒë·∫ßu ti√™n v·ª´a upload
DATA_PATH = list(uploaded.keys())[0]
print("‚úÖ File ƒë√£ upload:", DATA_PATH)

import pandas as pd

def safe_read_csv(path: str):
    encodings_to_try = ["utf-8", "utf-8-sig", "latin1", "cp1252", "cp1258"]
    seps_to_try = [",", ";", "\t", "|"]

    for enc in encodings_to_try:
        for sep in seps_to_try:
            try:
                df = pd.read_csv(path, encoding=enc, sep=sep)
                print(f"‚úÖ ƒê·ªçc th√†nh c√¥ng v·ªõi encoding={enc}, sep='{sep}'")
                print("Shape:", df.shape)
                print("C√°c c·ªôt:", df.columns.tolist()[:10])
                return df
            except Exception:
                continue
    raise ValueError("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file CSV v·ªõi c√°c encoding/sep ph·ªï bi·∫øn.")

df = safe_read_csv(DATA_PATH)
df.head()

import numpy as np
import pandas as pd

assert "Score" in df.columns, "‚ùå Kh√¥ng th·∫•y c·ªôt 'Score' trong d·ªØ li·ªáu!"
y_raw = df["Score"]

def is_binary_series(s: pd.Series) -> bool:
    vals = pd.unique(s.dropna())
    return set(vals).issubset({0, 1})

target_is_binary = is_binary_series(y_raw)

if target_is_binary:
    print("‚úÖ 'Score' ƒë√£ nh·ªã ph√¢n (0/1) ‚Üí d√πng tr·ª±c ti·∫øp.")
    y = y_raw.astype(int)
    selected_threshold = None
else:
    # Classification-oriented: qu√©t c√°c ng∆∞·ª°ng v√† CH·ªåN ng∆∞·ª°ng sao cho t·ª∑ l·ªá l·ªõp g·∫ßn 50/50 nh·∫•t
    vals = y_raw.astype(float)
    lo, hi = vals.quantile(0.2), vals.quantile(0.8)  # tr√°nh outlier
    candidates = np.linspace(lo, hi, 51)
    best_thr, best_balance = candidates[0], -1
    for thr in candidates:
        y_tmp = (vals >= thr).astype(int)
        balance = 1 - abs(y_tmp.mean() - 0.5)*2  # 1= c√¢n b·∫±ng ho√†n h·∫£o, 0 = l·ªách h·∫≥n
        if balance > best_balance:
            best_balance, best_thr = balance, thr

    selected_threshold = float(best_thr)
    y = (vals >= selected_threshold).astype(int)
    print("‚ö†Ô∏è 'Score' l√† li√™n t·ª•c.")
    print(f"üëâ Ch·ªçn threshold (classification-oriented balance) = {selected_threshold:.4f} | "
          f"Class balance ‚âà {y.mean():.2%} (t·ª∑ l·ªá l·ªõp 1).")

X_raw = df.drop(columns=["Score"])
print("üìä X:", X_raw.shape, " | y:", y.shape)

# Ng∆∞·ªùi d√πng ch·ªâ ch·ªânh t·∫°i ƒë√¢y (ho·∫∑c gi·ªØ "Khuy·∫øn ngh·ªã")
USER_MLE = {
    "penalty": "Khuy·∫øn ngh·ªã",   # "Khuy·∫øn ngh·ªã" | "none" | "l2"
    "C":       "Khuy·∫øn ngh·ªã",   # "Khuy·∫øn ngh·ªã" | s·ªë (vd 1.0, 10.0, 1e6)
    "solver":  "Khuy·∫øn ngh·ªã"    # "Khuy·∫øn ngh·ªã" | "lbfgs" | "saga"
}

# Map khuy·∫øn ngh·ªã ‚Üí c·∫•u h√¨nh ph√π h·ª£p MLE
penalty = None if USER_MLE["penalty"] == "Khuy·∫øn ngh·ªã" else (None if USER_MLE["penalty"]=="none" else USER_MLE["penalty"])
C       = (1e6 if USER_MLE["C"] == "Khuy·∫øn ngh·ªã" else float(USER_MLE["C"]))  # C r·∫•t l·ªõn ~ MLE
solver  = ("lbfgs" if USER_MLE["solver"] == "Khuy·∫øn ngh·ªã" else USER_MLE["solver"])

print("‚öôÔ∏è Logistic (MLE) params ‚Üí", {"penalty": penalty, "C": C, "solver": solver})

# CELL 2 ‚Äî Ch·ªçn tham s·ªë MLE (c√≥ khuy·∫øn ngh·ªã & range)
# - penalty:  None (MLE, KH√ÅY KHUY·∫æN NGH·ªä)  ho·∫∑c 'l2' (Ridge)
# - C:        ƒë·ªô ‚Äún·ªõi l·ªèng‚Äù regularization. C r·∫•t l·ªõn ~ MLE. Range an to√†n: 1e-2 .. 1e8 (khuy·∫øn ngh·ªã: 1e6)
# - solver:   'lbfgs' (khuy·∫øn ngh·ªã) ho·∫∑c 'saga'
# - class_weight: None ho·∫∑c 'balanced' (khuy·∫øn ngh·ªã n·∫øu l·ªõp l·ªách)
# - test_size: 0.10 .. 0.40 (khuy·∫øn ngh·ªã 0.25)
# - random_state: 42 (gi·ªØ c·ªë ƒë·ªãnh ƒë·ªÉ t√°i l·∫≠p)

from IPython.display import display, Markdown
import math

try:
    import ipywidgets as widgets

    display(Markdown(r"""
**‚öôÔ∏è Tu·ª≥ ch·ªçn tham s·ªë cho Logistic Regression (MLE)**

**Khuy·∫øn ngh·ªã (an to√†n & t·ªïng qu√°t):**
- `penalty` = **None** *(kh√¥ng ph·∫°t ‚Üí MLE thu·∫ßn)*
- `C` = **1e6** *(r·∫•t l·ªõn ‚Üí g·∫ßn MLE)*
- `solver` = **lbfgs**
- `class_weight` = **balanced** *(n√™n d√πng n·∫øu class l·ªách)*
- `test_size` = **0.25**
- `random_state` = **42**

B·∫°n c√≥ th·ªÉ tu·ª≥ ch·ªânh trong ph·∫°m vi g·ª£i √Ω b√™n d∆∞·ªõi.
    """))

    # Widgets
    penalty_dd = widgets.Dropdown(
        options=[("MLE (kh√¥ng ph·∫°t)", "none"), ("L2 (Ridge)", "l2")],
        value="none", description="penalty"
    )

    # FloatLogSlider: 1e-2 .. 1e8
    C_slider = widgets.FloatLogSlider(
        base=10.0, min=-2, max=8, step=0.1, value=1e6,
        description="C (log10)"
    )
    C_help = widgets.Label("‚Ü≥ C r·∫•t l·ªõn ~ MLE (khuy·∫øn ngh·ªã: 1e6). Ph·∫°m vi: 1e-2 ‚Üí 1e8.")

    solver_dd = widgets.Dropdown(
        options=["lbfgs", "saga"],
        value="lbfgs", description="solver"
    )

    cw_dd = widgets.Dropdown(
        options=[("None", None), ("balanced", "balanced")],
        value="balanced", description="class_weight"
    )

    ts_slider = widgets.FloatSlider(
        min=0.10, max=0.40, step=0.01, value=0.25,
        readout_format=".2f", description="test_size"
    )

    rs_int = widgets.IntText(value=42, description="random_state")

    confirm_btn = widgets.Button(
        description="‚úÖ X√°c nh·∫≠n tham s·ªë",
        button_style="success"
    )
    out = widgets.Output()

    def on_confirm_clicked(b):
        with out:
            out.clear_output()
            # Map 'none' ‚Üí None theo sklearn
            penalty_val = None if penalty_dd.value == "none" else penalty_dd.value
            C_val = float(C_slider.value)
            solver_val = solver_dd.value
            class_weight_val = cw_dd.value
            test_size_val = float(ts_slider.value)
            random_state_val = int(rs_int.value)

            # R√†ng bu·ªôc m·ªÅm (clamp)
            C_val = max(1e-2, min(C_val, 1e8))
            test_size_val = max(0.10, min(test_size_val, 0.40))

            # L∆∞u c·∫•u h√¨nh d√πng cho Cell 3
            global USER_MLE
            USER_MLE = {
                "penalty": penalty_val,
                "C": C_val,
                "solver": solver_val,
                "class_weight": class_weight_val,
                "test_size": test_size_val,
                "random_state": random_state_val,
            }

            print("ƒê√É CH·ªåN THAM S·ªê MLE:")
            for k, v in USER_MLE.items():
                print(f" - {k}: {v}")
            print("\nüëâ Ti·∫øp t·ª•c ch·∫°y **Cell 3** ƒë·ªÉ hu·∫•n luy·ªán MLE theo c√°c tham s·ªë tr√™n.")

    confirm_btn.on_click(on_confirm_clicked)

    display(
        widgets.VBox([
            penalty_dd,
            widgets.HBox([C_slider]), C_help,
            solver_dd,
            cw_dd,
            ts_slider,
            rs_int,
            confirm_btn,
            out
        ])
    )

except Exception as _:
    # Fallback n·∫øu ipywidgets kh√¥ng kh·∫£ d·ª•ng ‚Üí cho ng∆∞·ªùi d√πng ƒëi·ªÅn tay (v·∫´n c√≥ khuy·∫øn ngh·ªã)
    print("‚ö†Ô∏è ipywidgets ch∆∞a s·∫µn. D√πng c·∫•u h√¨nh m·∫∑c ƒë·ªãnh c√≥ khuy·∫øn ngh·ªã, c√≥ th·ªÉ s·ª≠a s·ªë b√™n d∆∞·ªõi.")
    USER_MLE = {
        "penalty": None,       # None = MLE (khuy·∫øn ngh·ªã) | ho·∫∑c 'l2'
        "C": 1e6,              # 1e-2 .. 1e8 (khuy·∫øn ngh·ªã 1e6)
        "solver": "lbfgs",     # 'lbfgs' (khuy·∫øn ngh·ªã) | 'saga'
        "class_weight": "balanced",  # None | 'balanced'
        "test_size": 0.25,     # 0.10 .. 0.40
        "random_state": 42,
    }
    print("USER_MLE =", USER_MLE)
    print("üëâ Ti·∫øp t·ª•c ch·∫°y **Cell 3** ƒë·ªÉ hu·∫•n luy·ªán MLE theo c√°c tham s·ªë tr√™n.")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X_raw, y, test_size=0.25, random_state=42, stratify=y
)

# Preprocess
numeric_cols = [c for c in X_raw.columns if np.issubdtype(df[c].dtype, np.number)]
categorical_cols = [c for c in X_raw.columns if c not in numeric_cols]

numeric_tf = Pipeline([("imputer", SimpleImputer(strategy="median")),
                       ("scaler", StandardScaler())])
categorical_tf = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")),
                           ("onehot", OneHotEncoder(handle_unknown="ignore"))])

preprocess = ColumnTransformer([
    ("num", numeric_tf, numeric_cols),
    ("cat", categorical_tf, categorical_cols)
])

# Model (MLE ~ penalty=None ho·∫∑c C r·∫•t l·ªõn)
clf = LogisticRegression(max_iter=1000, penalty=penalty, C=C, solver=solver)

pipe = Pipeline([("preprocess", preprocess), ("clf", clf)])
pipe.fit(X_train, y_train)

# Evaluate
y_pred = pipe.predict(X_test)
metrics = {
    "Accuracy":  accuracy_score(y_test, y_pred),
    "Precision": precision_score(y_test, y_pred, zero_division=0),
    "Recall":    recall_score(y_test, y_pred, zero_division=0),
    "F1":        f1_score(y_test, y_pred, zero_division=0),
}
print("\nüìä Logistic Regression (MLE) metrics:")
for k,v in metrics.items():
    print(f"- {k}: {v:.3f}")
print("\nüîé Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# CELL 4 ‚Äî Gi·∫£i th√≠ch k·∫øt qu·∫£ + Top 5 bi·∫øn d∆∞∆°ng/√¢m + K·∫øt lu·∫≠n

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# 1) T√≠nh l·∫°i c√°c ch·ªâ s·ªë ƒë√°nh gi√° (ph√≤ng khi b·∫°n ch·∫°y cell 3 ƒë·ªôc l·∫≠p)
y_pred = pipe.predict(X_test)
try:
    y_proba = pipe.predict_proba(X_test)[:, 1]
except Exception:
    y_proba = None

acc  = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, zero_division=0)
rec  = recall_score(y_test, y_pred, zero_division=0)
f1   = f1_score(y_test, y_pred, zero_division=0)
cm   = confusion_matrix(y_test, y_pred)
auc  = roc_auc_score(y_test, y_proba) if y_proba is not None else None

print("üìä ƒê√ÅNH GI√Å M√î H√åNH (Logistic MLE)")
print(f"- Accuracy  : {acc:.3f}  ‚Üí T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n to√†n b·ªô m·∫´u")
print(f"- Precision : {prec:.3f}  ‚Üí Trong c√°c d·ª± ƒëo√°n '1', bao nhi√™u % l√† ƒë√∫ng (h·∫°n ch·∫ø false positive)")
print(f"- Recall    : {rec:.3f}  ‚Üí Trong c√°c m·∫´u '1' th·∫≠t, b·∫Øt ƒë∆∞·ª£c bao nhi√™u % (h·∫°n ch·∫ø false negative)")
print(f"- F1-score  : {f1:.3f}   ‚Üí Trung ho√† Precision & Recall (ph√π h·ª£p khi d·ªØ li·ªáu l·ªách l·ªõp)")
if auc is not None:
    print(f"- ROC AUC   : {auc:.3f}  ‚Üí Kh·∫£ nƒÉng x·∫øp h·∫°ng x√°c su·∫•t ƒë√∫ng (cao h∆°n t·ªët h∆°n)")
print("\nüîé Confusion Matrix [ [TN, FP], [FN, TP] ]:")
print(cm)

# 2) L·∫•y t√™n ƒë·∫∑c tr∆∞ng sau ColumnTransformer
preproc = pipe.named_steps["preprocess"]
clf     = pipe.named_steps["clf"]

# T√™n numeric gi·ªØ nguy√™n, t√™n categorical l·∫•y t·ª´ OneHotEncoder
num_cols = numeric_cols
ohe = preproc.named_transformers_["cat"].named_steps["onehot"]
cat_feature_names = list(ohe.get_feature_names_out(categorical_cols))
feature_names = list(num_cols) + cat_feature_names

# 3) H·ªá s·ªë c·ªßa Logistic (d·∫•u d∆∞∆°ng/√¢m cho bi·∫øt h∆∞·ªõng ·∫£nh h∆∞·ªüng)
coefs = clf.coef_.ravel()
coef_df = pd.DataFrame({"feature": feature_names, "coef": coefs})
coef_df["abs_coef"] = coef_df["coef"].abs()

# Top 5 d∆∞∆°ng & √¢m
top_pos = (coef_df.sort_values("coef", ascending=False)
                  .head(5)[["feature", "coef"]]
                  .reset_index(drop=True))
top_neg = (coef_df.sort_values("coef", ascending=True)
                  .head(5)[["feature", "coef"]]
                  .reset_index(drop=True))

print("\nüìà Top 5 bi·∫øn ·∫£nh h∆∞·ªüng D∆Ø∆†NG (coef > 0) ‚Äî tƒÉng x√°c su·∫•t l·ªõp '1':")
display(top_pos)

print("\nüìâ Top 5 bi·∫øn ·∫£nh h∆∞·ªüng √ÇM (coef < 0) ‚Äî gi·∫£m x√°c su·∫•t l·ªõp '1':")
display(top_neg)

# 4) K·∫øt lu·∫≠n ng·∫Øn g·ªçn b·∫±ng l·ªùi
pos_list = [f"{r.feature}" for _, r in top_pos.iterrows()]
neg_list = [f"{r.feature}" for _, r in top_neg.iterrows()]

print("\nüß≠ K·∫æT LU·∫¨N NG·∫ÆN G·ªåN")
if selected_threshold is not None:
    print(f"- Target 'Score' ban ƒë·∫ßu li√™n t·ª•c ‚Üí ƒë√£ ch·ªçn ng∆∞·ª°ng = {selected_threshold:.4f} (method: classification-oriented balance).")
else:
    print("- Target 'Score' ƒë√£ l√† nh·ªã ph√¢n, kh√¥ng c·∫ßn ch·ªçn ng∆∞·ª°ng.")

print(f"- Hi·ªáu su·∫•t t·ªïng quan: Accuracy={acc:.3f}, Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}" + (f", AUC={auc:.3f}" if auc is not None else ""))
if pos_list:
    print(f"- Bi·∫øn ·∫£nh h∆∞·ªüng **d∆∞∆°ng** (tƒÉng x√°c su·∫•t thu·ªôc l·ªõp '1'): {', '.join(pos_list)}.")
if neg_list:
    print(f"- Bi·∫øn ·∫£nh h∆∞·ªüng **√¢m** (gi·∫£m x√°c su·∫•t thu·ªôc l·ªõp '1'): {', '.join(neg_list)}.")

print("\nüí° Di·ªÖn gi·∫£i: V·ªõi Logistic Regression, h·ªá s·ªë d∆∞∆°ng nghƒ©a l√† khi bi·∫øn tƒÉng (gi·ªØ c√°c bi·∫øn kh√°c c·ªë ƒë·ªãnh) ‚Üí x√°c su·∫•t thu·ªôc l·ªõp '1' tƒÉng; h·ªá s·ªë √¢m th√¨ ng∆∞·ª£c l·∫°i.")

# CELL 5A ‚Äî Chu·∫©n b·ªã cho Bayesian Logistic Regression (PyMC)

# Y√™u c·∫ßu: ƒë√£ ch·∫°y Cell 1‚Äì3 (ƒë·ªÉ c√≥ X_train, X_test, y_train, y_test, pipe)
import numpy as np, pandas as pd

print("Bayesian Logistic s·∫Ω d√πng d·ªØ li·ªáu ƒë√£ t√°ch train/test ·ªü MLE ƒë·ªÉ so s√°nh c√¥ng b·∫±ng.")
print("Quy tr√¨nh:")
print("1) L·∫•y ma tr·∫≠n ƒë·∫∑c tr∆∞ng sau ti·ªÅn x·ª≠ l√Ω (gi·ªëng MLE).")
print("2) Khai b√°o prior Gaussian cho h·ªá s·ªë & intercept.")
print("3) Sampling b·∫±ng NUTS (PyMC) theo th√¥ng s·ªë b·∫°n ch·ªçn.")
print("4) Ch·∫•m ƒëi·ªÉm tr√™n test set + top bi·∫øn d∆∞∆°ng/√¢m + k·∫øt lu·∫≠n.")

# L·∫•y transformer ƒë√£ fit trong MLE
preproc = pipe.named_steps["preprocess"]
Xt_train = preproc.transform(X_train)
Xt_test  = preproc.transform(X_test)

# T√™n ƒë·∫∑c tr∆∞ng sau OneHot
ohe = preproc.named_transformers_["cat"].named_steps["onehot"]
feature_names = list(numeric_cols) + list(ohe.get_feature_names_out(categorical_cols))

Xt_train.shape, Xt_test.shape, len(feature_names)

# CELL 5B ‚Äî Ch·ªçn tham s·ªë Bayesian (c√≥ khuy·∫øn ngh·ªã & range)
# Th√¥ng s·ªë c√≥ th·ªÉ ch·ªânh:
# - prior_sigma_beta: ƒë·ªô l·ªách chu·∫©n c·ªßa prior cho h·ªá s·ªë (khuy·∫øn ngh·ªã: 10.0)
# - prior_sigma_intercept: ƒë·ªô l·ªách chu·∫©n c·ªßa prior cho intercept (khuy·∫øn ngh·ªã: 10.0)
# - draws: s·ªë m·∫´u posterior sau warmup (khuy·∫øn ngh·ªã: 1000; DEMO nhanh: 500)
# - tune: s·ªë m·∫´u warmup (khuy·∫øn ngh·ªã: 1000; DEMO nhanh: 500)
# - target_accept: 0.9 ~ 0.95 (cao h∆°n ‚Üí an to√†n h∆°n nh∆∞ng ch·∫≠m h∆°n)
# - chains: 2 (khuy·∫øn ngh·ªã cho b√°o c√°o; 1 cho demo nhanh)
# - cores: 1 (Colab ·ªïn ƒë·ªãnh)
# - random_seed: 42 (t√°i l·∫≠p)
# - mode: "Khuy·∫øn ngh·ªã" | "Nhanh (demo)"

from IPython.display import display, Markdown

try:
    import ipywidgets as widgets

    display(Markdown(r"""
**‚öôÔ∏è Tu·ª≥ ch·ªçn th√¥ng s·ªë cho Bayesian Logistic (PyMC)**

**Khuy·∫øn ngh·ªã (chu·∫©n b√°o c√°o):**
- `prior_sigma_beta` = **10.0**
- `prior_sigma_intercept` = **10.0**
- `draws` = **1000**, `tune` = **1000**
- `target_accept` = **0.90**
- `chains` = **2**, `cores` = **1**, `random_seed` = **42**

**Nhanh (demo):**
- `draws` = **500**, `tune` = **500**, `chains` = **1**
    """))

    mode_dd = widgets.Dropdown(
        options=[("Khuy·∫øn ngh·ªã (chu·∫©n b√°o c√°o)", "rec"), ("Nhanh (demo)", "demo")],
        value="rec", description="Ch·∫ø ƒë·ªô"
    )

    prior_beta = widgets.FloatLogSlider(base=10, min=-1, max=2, step=0.1, value=10.0,
                                        description="prior_sigma_beta")
    prior_intc = widgets.FloatLogSlider(base=10, min=-1, max=2, step=0.1, value=10.0,
                                        description="prior_sigma_intercept")
    draws = widgets.IntSlider(min=200, max=3000, step=50, value=1000, description="draws")
    tune  = widgets.IntSlider(min=200, max=3000, step=50, value=1000, description="tune")
    targ  = widgets.FloatSlider(min=0.80, max=0.98, step=0.01, value=0.90, description="target_accept")
    chains = widgets.IntSlider(min=1, max=4, step=1, value=2, description="chains")
    cores  = widgets.IntSlider(min=1, max=2, step=1, value=1, description="cores")
    seed   = widgets.IntText(value=42, description="random_seed")

    def on_mode_change(change):
        if change["new"] == "demo":
            draws.value, tune.value, chains.value = 500, 500, 1
        else:
            draws.value, tune.value, chains.value = 1000, 1000, 2

    mode_dd.observe(on_mode_change, names="value")

    confirm = widgets.Button(description="‚úÖ X√°c nh·∫≠n th√¥ng s·ªë", button_style="success")
    out = widgets.Output()

    def on_confirm(_):
        with out:
            out.clear_output()
            global BAYES_CFG
            BAYES_CFG = {
                "prior_sigma_beta": float(max(0.1, min(prior_beta.value, 100.0))),
                "prior_sigma_intercept": float(max(0.1, min(prior_intc.value, 100.0))),
                "draws": int(max(200, min(draws.value, 3000))),
                "tune": int(max(200, min(tune.value, 3000))),
                "target_accept": float(max(0.80, min(targ.value, 0.98))),
                "chains": int(max(1, min(chains.value, 4))),
                "cores": int(max(1, min(cores.value, 2))),
                "random_seed": int(seed.value),
            }
            print("ƒê√É CH·ªåN TH√îNG S·ªê BAYESIAN:")
            for k, v in BAYES_CFG.items():
                print(f" - {k}: {v}")
            print("\nüëâ Ch·∫°y **Cell 5C** ƒë·ªÉ hu·∫•n luy·ªán & ƒë√°nh gi√° Bayesian.")

    confirm.on_click(on_confirm)

    display(widgets.VBox([
        mode_dd,
        prior_beta, prior_intc,
        draws, tune, targ,
        chains, cores, seed,
        confirm, out
    ]))

except Exception:
    print("‚ö†Ô∏è ipywidgets ch∆∞a s·∫µn. D√πng c·∫•u h√¨nh khuy·∫øn ngh·ªã b√™n d∆∞·ªõi, c√≥ th·ªÉ ch·ªânh s·ªë n·∫øu mu·ªën.")
    BAYES_CFG = {
        "prior_sigma_beta": 10.0,
        "prior_sigma_intercept": 10.0,
        "draws": 1000,
        "tune": 1000,
        "target_accept": 0.90,
        "chains": 2,
        "cores": 1,
        "random_seed": 42,
    }
    print("BAYES_CFG =", BAYES_CFG)
    print("üëâ Ch·∫°y **Cell 5C** ƒë·ªÉ hu·∫•n luy·ªán & ƒë√°nh gi√° Bayesian.")

# CELL 5C ‚Äî Hu·∫•n luy·ªán Bayesian Logistic theo BAYES_CFG, ƒë√°nh gi√° & k·∫øt lu·∫≠n

import pymc as pm, arviz as az
import numpy as np, pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

assert "BAYES_CFG" in globals(), "Ch∆∞a c√≥ BAYES_CFG. H√£y ch·∫°y Cell 5B v√† b·∫•m 'X√°c nh·∫≠n tham s·ªë'."

with pm.Model() as bayes_logit:
    beta = pm.Normal("beta", mu=0, sigma=BAYES_CFG["prior_sigma_beta"], shape=Xt_train.shape[1])
    intercept = pm.Normal("intercept", mu=0, sigma=BAYES_CFG["prior_sigma_intercept"])
    logits = intercept + pm.math.dot(Xt_train, beta)
    p = pm.math.sigmoid(logits)
    y_obs = pm.Bernoulli("y_obs", p=p, observed=y_train.values)

    idata = pm.sample(
        draws=BAYES_CFG["draws"], tune=BAYES_CFG["tune"],
        target_accept=BAYES_CFG["target_accept"],
        chains=BAYES_CFG["chains"], cores=BAYES_CFG["cores"],
        random_seed=BAYES_CFG["random_seed"],
        progressbar=True
    )

print("‚úÖ Bayesian model fitted.")
summary = az.summary(idata, var_names=["beta","intercept"], round_to=3)
display(summary.head())

# Posterior mean ‚Üí d·ª± ƒëo√°n test
beta_mean = idata.posterior["beta"].mean(dim=("chain","draw")).values
intercept_mean = idata.posterior["intercept"].mean(dim=("chain","draw")).values
logits_test = intercept_mean + Xt_test @ beta_mean
proba_bayes = 1/(1+np.exp(-logits_test))
y_pred_bayes = (proba_bayes >= 0.5).astype(int)

# ƒê√°nh gi√°
acc_b  = accuracy_score(y_test, y_pred_bayes)
prec_b = precision_score(y_test, y_pred_bayes, zero_division=0)
rec_b  = recall_score(y_test, y_pred_bayes, zero_division=0)
f1_b   = f1_score(y_test, y_pred_bayes, zero_division=0)
auc_b  = roc_auc_score(y_test, proba_bayes)

print("\nüìä ƒê√ÅNH GI√Å (Bayesian Logistic)")
print(f"- Accuracy  : {acc_b:.3f}")
print(f"- Precision : {prec_b:.3f}")
print(f"- Recall    : {rec_b:.3f}")
print(f"- F1-score  : {f1_b:.3f}")
print(f"- ROC AUC   : {auc_b:.3f}")

# Top 5 d∆∞∆°ng/√¢m theo posterior mean
coef_df_b = pd.DataFrame({"feature": feature_names, "coef": beta_mean})
top_pos_b = coef_df_b.sort_values("coef", ascending=False).head(5)[["feature","coef"]]
top_neg_b = coef_df_b.sort_values("coef", ascending=True).head(5)[["feature","coef"]]

print("\nüìà Top 5 bi·∫øn D∆Ø∆†NG (Bayesian):")
display(top_pos_b)
print("\nüìâ Top 5 bi·∫øn √ÇM (Bayesian):")
display(top_neg_b)

# K·∫øt lu·∫≠n b·∫±ng l·ªùi
pos_list = top_pos_b["feature"].tolist()
neg_list = top_neg_b["feature"].tolist()

print("\nüß≠ K·∫æT LU·∫¨N (Bayesian)")
if selected_threshold is not None:
    print(f"- Target 'Score' ban ƒë·∫ßu li√™n t·ª•c ‚Üí ƒë√£ ch·ªçn ng∆∞·ª°ng = {selected_threshold:.4f} (classification-oriented balance).")
else:
    print("- Target 'Score' ƒë√£ nh·ªã ph√¢n s·∫µn, kh√¥ng threshold.")

print(f"- Hi·ªáu su·∫•t: Accuracy={acc_b:.3f}, Precision={prec_b:.3f}, Recall={rec_b:.3f}, F1={f1_b:.3f}, AUC={auc_b:.3f}")
if pos_list: print(f"- Bi·∫øn **d∆∞∆°ng** (tƒÉng x√°c su·∫•t l·ªõp '1'): {', '.join(pos_list)}.")
if neg_list: print(f"- Bi·∫øn **√¢m** (gi·∫£m x√°c su·∫•t l·ªõp '1'): {', '.join(neg_list)}.")
print("\nüí° ∆Øu ƒëi·ªÉm Bayesian: c√≥ posterior & credible intervals (xem b·∫£ng summary) ƒë·ªÉ ƒë√°nh gi√° m·ª©c ƒë·ªô ch·∫Øc ch·∫Øn c·ªßa t·ª´ng bi·∫øn.")

# CELL 5D ‚Äî Di·ªÖn gi·∫£i Bayesian b·∫±ng % v√† nh√≥m bi·∫øn (ch·∫Øc ch·∫Øn d∆∞∆°ng/√¢m/kh√¥ng x√°c ƒë·ªãnh)

import numpy as np
import pandas as pd
import arviz as az
from IPython.display import display

# Ki·ªÉm tra d·ªØ li·ªáu c·∫ßn thi·∫øt
assert "idata" in globals(), "‚ùå Ch∆∞a c√≥ 'idata'. H√£y ch·∫°y Cell 5C tr∆∞·ªõc."
assert "feature_names" in globals(), "‚ùå Thi·∫øu 'feature_names'. H√£y ch·∫Øc ƒë√£ ch·∫°y 5A/5C."

# L·∫•y m·∫´u posterior c·ªßa beta: shape (chains, draws, K) ‚Üí (samples, K)
beta_draws = idata.posterior["beta"].values  # dims: (chain, draw, K)
chains, draws, K = beta_draws.shape
beta_samples = beta_draws.reshape(chains * draws, K)

# T√≠nh th·ªëng k√™ cho t·ª´ng feature
means = beta_samples.mean(axis=0)
sds   = beta_samples.std(axis=0)
ci_l  = np.quantile(beta_samples, 0.025, axis=0)
ci_u  = np.quantile(beta_samples, 0.975, axis=0)

# X√°c su·∫•t d·∫•u
p_pos = (beta_samples > 0).mean(axis=0)  # P(beta > 0)
p_neg = 1.0 - p_pos

df_bayes = pd.DataFrame({
    "feature": feature_names,
    "mean": means,
    "sd": sds,
    "ci_2.5%": ci_l,
    "ci_97.5%": ci_u,
    "P(beta>0)": p_pos,
    "P(beta<0)": p_neg
})

# Ph√¢n lo·∫°i theo ‚Äúƒë·ªô ch·∫Øc ch·∫Øn‚Äù
# - Ch·∫Øc ch·∫Øn d∆∞∆°ng: CI th·∫•p > 0 ho·∫∑c P(beta>0) >= 0.975
# - Ch·∫Øc ch·∫Øn √¢m   : CI cao  < 0 ho·∫∑c P(beta<0) >= 0.975
# - Kh√¥ng x√°c ƒë·ªãnh : c√≤n l·∫°i (CI c·∫Øt 0), ∆∞u ti√™n P(beta>0) ~ 0.5
certain_pos_mask = (df_bayes["ci_2.5%"] > 0) | (df_bayes["P(beta>0)"] >= 0.975)
certain_neg_mask = (df_bayes["ci_97.5%"] < 0) | (df_bayes["P(beta<0)"] >= 0.975)
uncertain_mask   = ~(certain_pos_mask | certain_neg_mask)

df_bayes["category"] = np.where(
    certain_pos_mask, "certain_positive",
    np.where(certain_neg_mask, "certain_negative", "uncertain")
)

# S·∫Øp x·∫øp ƒë·ªÉ l·∫•y top
# - D∆∞∆°ng/√Çm: theo |mean| gi·∫£m d·∫ßn (t√°c ƒë·ªông m·∫°nh h∆°n)
# - Kh√¥ng x√°c ƒë·ªãnh: theo |P(beta>0) - 0.5| tƒÉng d·∫ßn (g·∫ßn 50% ‚Üí m∆° h·ªì h∆°n)
top_pos = (df_bayes[df_bayes["category"] == "certain_positive"]
           .sort_values("mean", ascending=False)
           .head(5))
top_neg = (df_bayes[df_bayes["category"] == "certain_negative"]
           .sort_values("mean", ascending=True)
           .head(5))
uncertain_sorted = (df_bayes[df_bayes["category"] == "uncertain"]
                    .assign(uncert_score=(df_bayes["P(beta>0)"] - 0.5).abs())
                    .sort_values("uncert_score", ascending=True)
                    .head(5))

# B·∫£ng ph·∫ßn trƒÉm g·ªçn g√†ng
def fmt_pct(x): return f"{x*100:,.1f}%"
view_cols = ["feature", "mean", "sd", "ci_2.5%", "ci_97.5%", "P(beta>0)", "P(beta<0)"]

print("üìä B·∫¢NG T√ìM T·∫ÆT POSTERIOR (m·ªôt ph·∫ßn, top theo |mean|):")
display(df_bayes.reindex(df_bayes["mean"].abs().sort_values(ascending=False).index)
        [view_cols].head(12)
        .assign(**{"P(beta>0)": df_bayes["P(beta>0)"].head(12).map(fmt_pct),
                   "P(beta<0)": df_bayes["P(beta<0)"].head(12).map(fmt_pct)}))

print("\n‚úÖ Top bi·∫øn **ch·∫Øc ch·∫Øn D∆Ø∆†NG** (CI95% > 0 ho·∫∑c P(Œ≤>0)‚â•97.5%):")
if len(top_pos):
    display(top_pos[view_cols].assign(**{
        "P(beta>0)": top_pos["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": top_pos["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(kh√¥ng ƒë·ªß bi·∫øn th·ªèa ƒëi·ªÅu ki·ªán)")

print("\n‚úÖ Top bi·∫øn **ch·∫Øc ch·∫Øn √ÇM** (CI95% < 0 ho·∫∑c P(Œ≤<0)‚â•97.5%):")
if len(top_neg):
    display(top_neg[view_cols].assign(**{
        "P(beta>0)": top_neg["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": top_neg["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(kh√¥ng ƒë·ªß bi·∫øn th·ªèa ƒëi·ªÅu ki·ªán)")

print("\n‚öñÔ∏è Top bi·∫øn **KH√îNG X√ÅC ƒê·ªäNH** (CI c·∫Øt 0, P(Œ≤>0) g·∫ßn 50%):")
if len(uncertain_sorted):
    display(uncertain_sorted[view_cols].assign(**{
        "P(beta>0)": uncertain_sorted["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": uncertain_sorted["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(kh√¥ng ƒë·ªß bi·∫øn thu·ªôc nh√≥m m∆° h·ªì)")

# K·∫øt lu·∫≠n ng·∫Øn g·ªçn b·∫±ng l·ªùi
pos_names = ", ".join(top_pos["feature"].tolist()[:5]) if len(top_pos) else "kh√¥ng c√≥"
neg_names = ", ".join(top_neg["feature"].tolist()[:5]) if len(top_neg) else "kh√¥ng c√≥"
unc_names = ", ".join(uncertain_sorted["feature"].tolist()[:5]) if len(uncertain_sorted) else "kh√¥ng c√≥"

print("\nüß≠ K·∫æT LU·∫¨N (Bayesian ‚Äì theo posterior 95% & x√°c su·∫•t d·∫•u)")
if selected_threshold is not None:
    print(f"- Target 'Score' ban ƒë·∫ßu li√™n t·ª•c ‚Üí ng∆∞·ª°ng = {selected_threshold:.4f} (classification balance).")
else:
    print("- Target 'Score' ƒë√£ nh·ªã ph√¢n, kh√¥ng c·∫ßn threshold.")
print(f"- Bi·∫øn **ch·∫Øc ch·∫Øn d∆∞∆°ng**: {pos_names}.")
print(f"- Bi·∫øn **ch·∫Øc ch·∫Øn √¢m**: {neg_names}.")
print(f"- Bi·∫øn **ch∆∞a r√µ (m∆° h·ªì)**: {unc_names}.")
print("üí° Di·ªÖn gi·∫£i: v·ªõi bi·∫øn ch·∫Øc ch·∫Øn d∆∞∆°ng/√¢m, credible interval 95% kh√¥ng c·∫Øt 0 (ho·∫∑c x√°c su·∫•t d·∫•u ‚â• 97.5%),\n"
      "c√≤n nh√≥m m∆° h·ªì c√≥ x√°c su·∫•t d·∫•u ~50%, c·∫ßn th√™m d·ªØ li·ªáu ho·∫∑c m√¥ h√¨nh kh√°c ƒë·ªÉ kh·∫≥ng ƒë·ªãnh.")