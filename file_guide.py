# -*- coding: utf-8 -*-
"""File guide

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/136px56zpdFZ908qZ8znJYQswKbnFRXhw
"""

!pip install -q \
    "numpy==2.0.2" \
    "pandas==2.2.2" \
    "scipy==1.13.1" \
    "scikit-learn==1.5.2" \
    "statsmodels==0.14.2" \
    "matplotlib" \
    "pymc" \
    "arviz"

import numpy as np, pandas as pd, matplotlib, scipy, statsmodels, sklearn
import pymc as pm, arviz as az

print("numpy       :", np.__version__)
print("pandas      :", pd.__version__)
print("scipy       :", scipy.__version__)
print("sklearn     :", sklearn.__version__)
print("statsmodels :", statsmodels.__version__)
print("pymc        :", pm.__version__)
print("arviz       :", az.__version__)

from google.colab import files

print("ğŸ“‚ Chá»n file CSV Ä‘á»ƒ upload...")
uploaded = files.upload()

# Láº¥y tÃªn file Ä‘áº§u tiÃªn vá»«a upload
DATA_PATH = list(uploaded.keys())[0]
print("âœ… File Ä‘Ã£ upload:", DATA_PATH)

import pandas as pd

def safe_read_csv(path: str):
    encodings_to_try = ["utf-8", "utf-8-sig", "latin1", "cp1252", "cp1258"]
    seps_to_try = [",", ";", "\t", "|"]

    for enc in encodings_to_try:
        for sep in seps_to_try:
            try:
                df = pd.read_csv(path, encoding=enc, sep=sep)
                print(f"âœ… Äá»c thÃ nh cÃ´ng vá»›i encoding={enc}, sep='{sep}'")
                print("Shape:", df.shape)
                print("CÃ¡c cá»™t:", df.columns.tolist()[:10])
                return df
            except Exception:
                continue
    raise ValueError("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c file CSV vá»›i cÃ¡c encoding/sep phá»• biáº¿n.")

df = safe_read_csv(DATA_PATH)
df.head()

import numpy as np
import pandas as pd

assert "Score" in df.columns, "âŒ KhÃ´ng tháº¥y cá»™t 'Score' trong dá»¯ liá»‡u!"
y_raw = df["Score"]

def is_binary_series(s: pd.Series) -> bool:
    vals = pd.unique(s.dropna())
    return set(vals).issubset({0, 1})

target_is_binary = is_binary_series(y_raw)

if target_is_binary:
    print("âœ… 'Score' Ä‘Ã£ nhá»‹ phÃ¢n (0/1) â†’ dÃ¹ng trá»±c tiáº¿p.")
    y = y_raw.astype(int)
    selected_threshold = None
else:
    # Classification-oriented: quÃ©t cÃ¡c ngÆ°á»¡ng vÃ  CHá»ŒN ngÆ°á»¡ng sao cho tá»· lá»‡ lá»›p gáº§n 50/50 nháº¥t
    vals = y_raw.astype(float)
    lo, hi = vals.quantile(0.2), vals.quantile(0.8)  # trÃ¡nh outlier
    candidates = np.linspace(lo, hi, 51)
    best_thr, best_balance = candidates[0], -1
    for thr in candidates:
        y_tmp = (vals >= thr).astype(int)
        balance = 1 - abs(y_tmp.mean() - 0.5)*2  # 1= cÃ¢n báº±ng hoÃ n háº£o, 0 = lá»‡ch háº³n
        if balance > best_balance:
            best_balance, best_thr = balance, thr

    selected_threshold = float(best_thr)
    y = (vals >= selected_threshold).astype(int)
    print("âš ï¸ 'Score' lÃ  liÃªn tá»¥c.")
    print(f"ğŸ‘‰ Chá»n threshold (classification-oriented balance) = {selected_threshold:.4f} | "
          f"Class balance â‰ˆ {y.mean():.2%} (tá»· lá»‡ lá»›p 1).")

X_raw = df.drop(columns=["Score"])
print("ğŸ“Š X:", X_raw.shape, " | y:", y.shape)

# NgÆ°á»i dÃ¹ng chá»‰ chá»‰nh táº¡i Ä‘Ã¢y (hoáº·c giá»¯ "Khuyáº¿n nghá»‹")
USER_MLE = {
    "penalty": "Khuyáº¿n nghá»‹",   # "Khuyáº¿n nghá»‹" | "none" | "l2"
    "C":       "Khuyáº¿n nghá»‹",   # "Khuyáº¿n nghá»‹" | sá»‘ (vd 1.0, 10.0, 1e6)
    "solver":  "Khuyáº¿n nghá»‹"    # "Khuyáº¿n nghá»‹" | "lbfgs" | "saga"
}

# Map khuyáº¿n nghá»‹ â†’ cáº¥u hÃ¬nh phÃ¹ há»£p MLE
penalty = None if USER_MLE["penalty"] == "Khuyáº¿n nghá»‹" else (None if USER_MLE["penalty"]=="none" else USER_MLE["penalty"])
C       = (1e6 if USER_MLE["C"] == "Khuyáº¿n nghá»‹" else float(USER_MLE["C"]))  # C ráº¥t lá»›n ~ MLE
solver  = ("lbfgs" if USER_MLE["solver"] == "Khuyáº¿n nghá»‹" else USER_MLE["solver"])

print("âš™ï¸ Logistic (MLE) params â†’", {"penalty": penalty, "C": C, "solver": solver})

# CELL 2 â€” Chá»n tham sá»‘ MLE (cÃ³ khuyáº¿n nghá»‹ & range)
# - penalty:  None (MLE, KHÃY KHUYáº¾N NGHá»Š)  hoáº·c 'l2' (Ridge)
# - C:        Ä‘á»™ â€œná»›i lá»ngâ€ regularization. C ráº¥t lá»›n ~ MLE. Range an toÃ n: 1e-2 .. 1e8 (khuyáº¿n nghá»‹: 1e6)
# - solver:   'lbfgs' (khuyáº¿n nghá»‹) hoáº·c 'saga'
# - class_weight: None hoáº·c 'balanced' (khuyáº¿n nghá»‹ náº¿u lá»›p lá»‡ch)
# - test_size: 0.10 .. 0.40 (khuyáº¿n nghá»‹ 0.25)
# - random_state: 42 (giá»¯ cá»‘ Ä‘á»‹nh Ä‘á»ƒ tÃ¡i láº­p)

from IPython.display import display, Markdown
import math

try:
    import ipywidgets as widgets

    display(Markdown(r"""
**âš™ï¸ Tuá»³ chá»n tham sá»‘ cho Logistic Regression (MLE)**

**Khuyáº¿n nghá»‹ (an toÃ n & tá»•ng quÃ¡t):**
- `penalty` = **None** *(khÃ´ng pháº¡t â†’ MLE thuáº§n)*
- `C` = **1e6** *(ráº¥t lá»›n â†’ gáº§n MLE)*
- `solver` = **lbfgs**
- `class_weight` = **balanced** *(nÃªn dÃ¹ng náº¿u class lá»‡ch)*
- `test_size` = **0.25**
- `random_state` = **42**

Báº¡n cÃ³ thá»ƒ tuá»³ chá»‰nh trong pháº¡m vi gá»£i Ã½ bÃªn dÆ°á»›i.
    """))

    # Widgets
    penalty_dd = widgets.Dropdown(
        options=[("MLE (khÃ´ng pháº¡t)", "none"), ("L2 (Ridge)", "l2")],
        value="none", description="penalty"
    )

    # FloatLogSlider: 1e-2 .. 1e8
    C_slider = widgets.FloatLogSlider(
        base=10.0, min=-2, max=8, step=0.1, value=1e6,
        description="C (log10)"
    )
    C_help = widgets.Label("â†³ C ráº¥t lá»›n ~ MLE (khuyáº¿n nghá»‹: 1e6). Pháº¡m vi: 1e-2 â†’ 1e8.")

    solver_dd = widgets.Dropdown(
        options=["lbfgs", "saga"],
        value="lbfgs", description="solver"
    )

    cw_dd = widgets.Dropdown(
        options=[("None", None), ("balanced", "balanced")],
        value="balanced", description="class_weight"
    )

    ts_slider = widgets.FloatSlider(
        min=0.10, max=0.40, step=0.01, value=0.25,
        readout_format=".2f", description="test_size"
    )

    rs_int = widgets.IntText(value=42, description="random_state")

    confirm_btn = widgets.Button(
        description="âœ… XÃ¡c nháº­n tham sá»‘",
        button_style="success"
    )
    out = widgets.Output()

    def on_confirm_clicked(b):
        with out:
            out.clear_output()
            # Map 'none' â†’ None theo sklearn
            penalty_val = None if penalty_dd.value == "none" else penalty_dd.value
            C_val = float(C_slider.value)
            solver_val = solver_dd.value
            class_weight_val = cw_dd.value
            test_size_val = float(ts_slider.value)
            random_state_val = int(rs_int.value)

            # RÃ ng buá»™c má»m (clamp)
            C_val = max(1e-2, min(C_val, 1e8))
            test_size_val = max(0.10, min(test_size_val, 0.40))

            # LÆ°u cáº¥u hÃ¬nh dÃ¹ng cho Cell 3
            global USER_MLE
            USER_MLE = {
                "penalty": penalty_val,
                "C": C_val,
                "solver": solver_val,
                "class_weight": class_weight_val,
                "test_size": test_size_val,
                "random_state": random_state_val,
            }

            print("ÄÃƒ CHá»ŒN THAM Sá» MLE:")
            for k, v in USER_MLE.items():
                print(f" - {k}: {v}")
            print("\nğŸ‘‰ Tiáº¿p tá»¥c cháº¡y **Cell 3** Ä‘á»ƒ huáº¥n luyá»‡n MLE theo cÃ¡c tham sá»‘ trÃªn.")

    confirm_btn.on_click(on_confirm_clicked)

    display(
        widgets.VBox([
            penalty_dd,
            widgets.HBox([C_slider]), C_help,
            solver_dd,
            cw_dd,
            ts_slider,
            rs_int,
            confirm_btn,
            out
        ])
    )

except Exception as _:
    # Fallback náº¿u ipywidgets khÃ´ng kháº£ dá»¥ng â†’ cho ngÆ°á»i dÃ¹ng Ä‘iá»n tay (váº«n cÃ³ khuyáº¿n nghá»‹)
    print("âš ï¸ ipywidgets chÆ°a sáºµn. DÃ¹ng cáº¥u hÃ¬nh máº·c Ä‘á»‹nh cÃ³ khuyáº¿n nghá»‹, cÃ³ thá»ƒ sá»­a sá»‘ bÃªn dÆ°á»›i.")
    USER_MLE = {
        "penalty": None,       # None = MLE (khuyáº¿n nghá»‹) | hoáº·c 'l2'
        "C": 1e6,              # 1e-2 .. 1e8 (khuyáº¿n nghá»‹ 1e6)
        "solver": "lbfgs",     # 'lbfgs' (khuyáº¿n nghá»‹) | 'saga'
        "class_weight": "balanced",  # None | 'balanced'
        "test_size": 0.25,     # 0.10 .. 0.40
        "random_state": 42,
    }
    print("USER_MLE =", USER_MLE)
    print("ğŸ‘‰ Tiáº¿p tá»¥c cháº¡y **Cell 3** Ä‘á»ƒ huáº¥n luyá»‡n MLE theo cÃ¡c tham sá»‘ trÃªn.")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X_raw, y, test_size=0.25, random_state=42, stratify=y
)

# Preprocess
numeric_cols = [c for c in X_raw.columns if np.issubdtype(df[c].dtype, np.number)]
categorical_cols = [c for c in X_raw.columns if c not in numeric_cols]

numeric_tf = Pipeline([("imputer", SimpleImputer(strategy="median")),
                       ("scaler", StandardScaler())])
categorical_tf = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")),
                           ("onehot", OneHotEncoder(handle_unknown="ignore"))])

preprocess = ColumnTransformer([
    ("num", numeric_tf, numeric_cols),
    ("cat", categorical_tf, categorical_cols)
])

# Model (MLE ~ penalty=None hoáº·c C ráº¥t lá»›n)
clf = LogisticRegression(max_iter=1000, penalty=penalty, C=C, solver=solver)

pipe = Pipeline([("preprocess", preprocess), ("clf", clf)])
pipe.fit(X_train, y_train)

# Evaluate
y_pred = pipe.predict(X_test)
metrics = {
    "Accuracy":  accuracy_score(y_test, y_pred),
    "Precision": precision_score(y_test, y_pred, zero_division=0),
    "Recall":    recall_score(y_test, y_pred, zero_division=0),
    "F1":        f1_score(y_test, y_pred, zero_division=0),
}
print("\nğŸ“Š Logistic Regression (MLE) metrics:")
for k,v in metrics.items():
    print(f"- {k}: {v:.3f}")
print("\nğŸ” Confusion matrix:\n", confusion_matrix(y_test, y_pred))

# CELL 4 â€” Giáº£i thÃ­ch káº¿t quáº£ + Top 5 biáº¿n dÆ°Æ¡ng/Ã¢m + Káº¿t luáº­n

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# 1) TÃ­nh láº¡i cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ (phÃ²ng khi báº¡n cháº¡y cell 3 Ä‘á»™c láº­p)
y_pred = pipe.predict(X_test)
try:
    y_proba = pipe.predict_proba(X_test)[:, 1]
except Exception:
    y_proba = None

acc  = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, zero_division=0)
rec  = recall_score(y_test, y_pred, zero_division=0)
f1   = f1_score(y_test, y_pred, zero_division=0)
cm   = confusion_matrix(y_test, y_pred)
auc  = roc_auc_score(y_test, y_proba) if y_proba is not None else None

print("ğŸ“Š ÄÃNH GIÃ MÃ” HÃŒNH (Logistic MLE)")
print(f"- Accuracy  : {acc:.3f}  â†’ Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn toÃ n bá»™ máº«u")
print(f"- Precision : {prec:.3f}  â†’ Trong cÃ¡c dá»± Ä‘oÃ¡n '1', bao nhiÃªu % lÃ  Ä‘Ãºng (háº¡n cháº¿ false positive)")
print(f"- Recall    : {rec:.3f}  â†’ Trong cÃ¡c máº«u '1' tháº­t, báº¯t Ä‘Æ°á»£c bao nhiÃªu % (háº¡n cháº¿ false negative)")
print(f"- F1-score  : {f1:.3f}   â†’ Trung hoÃ  Precision & Recall (phÃ¹ há»£p khi dá»¯ liá»‡u lá»‡ch lá»›p)")
if auc is not None:
    print(f"- ROC AUC   : {auc:.3f}  â†’ Kháº£ nÄƒng xáº¿p háº¡ng xÃ¡c suáº¥t Ä‘Ãºng (cao hÆ¡n tá»‘t hÆ¡n)")
print("\nğŸ” Confusion Matrix [ [TN, FP], [FN, TP] ]:")
print(cm)

# 2) Láº¥y tÃªn Ä‘áº·c trÆ°ng sau ColumnTransformer
preproc = pipe.named_steps["preprocess"]
clf     = pipe.named_steps["clf"]

# TÃªn numeric giá»¯ nguyÃªn, tÃªn categorical láº¥y tá»« OneHotEncoder
num_cols = numeric_cols
ohe = preproc.named_transformers_["cat"].named_steps["onehot"]
cat_feature_names = list(ohe.get_feature_names_out(categorical_cols))
feature_names = list(num_cols) + cat_feature_names

# 3) Há»‡ sá»‘ cá»§a Logistic (dáº¥u dÆ°Æ¡ng/Ã¢m cho biáº¿t hÆ°á»›ng áº£nh hÆ°á»Ÿng)
coefs = clf.coef_.ravel()
coef_df = pd.DataFrame({"feature": feature_names, "coef": coefs})
coef_df["abs_coef"] = coef_df["coef"].abs()

# Top 5 dÆ°Æ¡ng & Ã¢m
top_pos = (coef_df.sort_values("coef", ascending=False)
                  .head(5)[["feature", "coef"]]
                  .reset_index(drop=True))
top_neg = (coef_df.sort_values("coef", ascending=True)
                  .head(5)[["feature", "coef"]]
                  .reset_index(drop=True))

print("\nğŸ“ˆ Top 5 biáº¿n áº£nh hÆ°á»Ÿng DÆ¯Æ NG (coef > 0) â€” tÄƒng xÃ¡c suáº¥t lá»›p '1':")
display(top_pos)

print("\nğŸ“‰ Top 5 biáº¿n áº£nh hÆ°á»Ÿng Ã‚M (coef < 0) â€” giáº£m xÃ¡c suáº¥t lá»›p '1':")
display(top_neg)

# 4) Káº¿t luáº­n ngáº¯n gá»n báº±ng lá»i
pos_list = [f"{r.feature}" for _, r in top_pos.iterrows()]
neg_list = [f"{r.feature}" for _, r in top_neg.iterrows()]

print("\nğŸ§­ Káº¾T LUáº¬N NGáº®N Gá»ŒN")
if selected_threshold is not None:
    print(f"- Target 'Score' ban Ä‘áº§u liÃªn tá»¥c â†’ Ä‘Ã£ chá»n ngÆ°á»¡ng = {selected_threshold:.4f} (method: classification-oriented balance).")
else:
    print("- Target 'Score' Ä‘Ã£ lÃ  nhá»‹ phÃ¢n, khÃ´ng cáº§n chá»n ngÆ°á»¡ng.")

print(f"- Hiá»‡u suáº¥t tá»•ng quan: Accuracy={acc:.3f}, Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}" + (f", AUC={auc:.3f}" if auc is not None else ""))
if pos_list:
    print(f"- Biáº¿n áº£nh hÆ°á»Ÿng **dÆ°Æ¡ng** (tÄƒng xÃ¡c suáº¥t thuá»™c lá»›p '1'): {', '.join(pos_list)}.")
if neg_list:
    print(f"- Biáº¿n áº£nh hÆ°á»Ÿng **Ã¢m** (giáº£m xÃ¡c suáº¥t thuá»™c lá»›p '1'): {', '.join(neg_list)}.")

print("\nğŸ’¡ Diá»…n giáº£i: Vá»›i Logistic Regression, há»‡ sá»‘ dÆ°Æ¡ng nghÄ©a lÃ  khi biáº¿n tÄƒng (giá»¯ cÃ¡c biáº¿n khÃ¡c cá»‘ Ä‘á»‹nh) â†’ xÃ¡c suáº¥t thuá»™c lá»›p '1' tÄƒng; há»‡ sá»‘ Ã¢m thÃ¬ ngÆ°á»£c láº¡i.")

# CELL 5A â€” Chuáº©n bá»‹ cho Bayesian Logistic Regression (PyMC)

# YÃªu cáº§u: Ä‘Ã£ cháº¡y Cell 1â€“3 (Ä‘á»ƒ cÃ³ X_train, X_test, y_train, y_test, pipe)
import numpy as np, pandas as pd

print("Bayesian Logistic sáº½ dÃ¹ng dá»¯ liá»‡u Ä‘Ã£ tÃ¡ch train/test á»Ÿ MLE Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng.")
print("Quy trÃ¬nh:")
print("1) Láº¥y ma tráº­n Ä‘áº·c trÆ°ng sau tiá»n xá»­ lÃ½ (giá»‘ng MLE).")
print("2) Khai bÃ¡o prior Gaussian cho há»‡ sá»‘ & intercept.")
print("3) Sampling báº±ng NUTS (PyMC) theo thÃ´ng sá»‘ báº¡n chá»n.")
print("4) Cháº¥m Ä‘iá»ƒm trÃªn test set + top biáº¿n dÆ°Æ¡ng/Ã¢m + káº¿t luáº­n.")

# Láº¥y transformer Ä‘Ã£ fit trong MLE
preproc = pipe.named_steps["preprocess"]
Xt_train = preproc.transform(X_train)
Xt_test  = preproc.transform(X_test)

# TÃªn Ä‘áº·c trÆ°ng sau OneHot
ohe = preproc.named_transformers_["cat"].named_steps["onehot"]
feature_names = list(numeric_cols) + list(ohe.get_feature_names_out(categorical_cols))

Xt_train.shape, Xt_test.shape, len(feature_names)

# CELL 5B â€” Chá»n tham sá»‘ Bayesian (cÃ³ khuyáº¿n nghá»‹ & range)
# ThÃ´ng sá»‘ cÃ³ thá»ƒ chá»‰nh:
# - prior_sigma_beta: Ä‘á»™ lá»‡ch chuáº©n cá»§a prior cho há»‡ sá»‘ (khuyáº¿n nghá»‹: 10.0)
# - prior_sigma_intercept: Ä‘á»™ lá»‡ch chuáº©n cá»§a prior cho intercept (khuyáº¿n nghá»‹: 10.0)
# - draws: sá»‘ máº«u posterior sau warmup (khuyáº¿n nghá»‹: 1000; DEMO nhanh: 500)
# - tune: sá»‘ máº«u warmup (khuyáº¿n nghá»‹: 1000; DEMO nhanh: 500)
# - target_accept: 0.9 ~ 0.95 (cao hÆ¡n â†’ an toÃ n hÆ¡n nhÆ°ng cháº­m hÆ¡n)
# - chains: 2 (khuyáº¿n nghá»‹ cho bÃ¡o cÃ¡o; 1 cho demo nhanh)
# - cores: 1 (Colab á»•n Ä‘á»‹nh)
# - random_seed: 42 (tÃ¡i láº­p)
# - mode: "Khuyáº¿n nghá»‹" | "Nhanh (demo)"

from IPython.display import display, Markdown

try:
    import ipywidgets as widgets

    display(Markdown(r"""
**âš™ï¸ Tuá»³ chá»n thÃ´ng sá»‘ cho Bayesian Logistic (PyMC)**

**Khuyáº¿n nghá»‹ (chuáº©n bÃ¡o cÃ¡o):**
- `prior_sigma_beta` = **10.0**
- `prior_sigma_intercept` = **10.0**
- `draws` = **1000**, `tune` = **1000**
- `target_accept` = **0.90**
- `chains` = **2**, `cores` = **1**, `random_seed` = **42**

**Nhanh (demo):**
- `draws` = **500**, `tune` = **500**, `chains` = **1**
    """))

    mode_dd = widgets.Dropdown(
        options=[("Khuyáº¿n nghá»‹ (chuáº©n bÃ¡o cÃ¡o)", "rec"), ("Nhanh (demo)", "demo")],
        value="rec", description="Cháº¿ Ä‘á»™"
    )

    prior_beta = widgets.FloatLogSlider(base=10, min=-1, max=2, step=0.1, value=10.0,
                                        description="prior_sigma_beta")
    prior_intc = widgets.FloatLogSlider(base=10, min=-1, max=2, step=0.1, value=10.0,
                                        description="prior_sigma_intercept")
    draws = widgets.IntSlider(min=200, max=3000, step=50, value=1000, description="draws")
    tune  = widgets.IntSlider(min=200, max=3000, step=50, value=1000, description="tune")
    targ  = widgets.FloatSlider(min=0.80, max=0.98, step=0.01, value=0.90, description="target_accept")
    chains = widgets.IntSlider(min=1, max=4, step=1, value=2, description="chains")
    cores  = widgets.IntSlider(min=1, max=2, step=1, value=1, description="cores")
    seed   = widgets.IntText(value=42, description="random_seed")

    def on_mode_change(change):
        if change["new"] == "demo":
            draws.value, tune.value, chains.value = 500, 500, 1
        else:
            draws.value, tune.value, chains.value = 1000, 1000, 2

    mode_dd.observe(on_mode_change, names="value")

    confirm = widgets.Button(description="âœ… XÃ¡c nháº­n thÃ´ng sá»‘", button_style="success")
    out = widgets.Output()

    def on_confirm(_):
        with out:
            out.clear_output()
            global BAYES_CFG
            BAYES_CFG = {
                "prior_sigma_beta": float(max(0.1, min(prior_beta.value, 100.0))),
                "prior_sigma_intercept": float(max(0.1, min(prior_intc.value, 100.0))),
                "draws": int(max(200, min(draws.value, 3000))),
                "tune": int(max(200, min(tune.value, 3000))),
                "target_accept": float(max(0.80, min(targ.value, 0.98))),
                "chains": int(max(1, min(chains.value, 4))),
                "cores": int(max(1, min(cores.value, 2))),
                "random_seed": int(seed.value),
            }
            print("ÄÃƒ CHá»ŒN THÃ”NG Sá» BAYESIAN:")
            for k, v in BAYES_CFG.items():
                print(f" - {k}: {v}")
            print("\nğŸ‘‰ Cháº¡y **Cell 5C** Ä‘á»ƒ huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡ Bayesian.")

    confirm.on_click(on_confirm)

    display(widgets.VBox([
        mode_dd,
        prior_beta, prior_intc,
        draws, tune, targ,
        chains, cores, seed,
        confirm, out
    ]))

except Exception:
    print("âš ï¸ ipywidgets chÆ°a sáºµn. DÃ¹ng cáº¥u hÃ¬nh khuyáº¿n nghá»‹ bÃªn dÆ°á»›i, cÃ³ thá»ƒ chá»‰nh sá»‘ náº¿u muá»‘n.")
    BAYES_CFG = {
        "prior_sigma_beta": 10.0,
        "prior_sigma_intercept": 10.0,
        "draws": 1000,
        "tune": 1000,
        "target_accept": 0.90,
        "chains": 2,
        "cores": 1,
        "random_seed": 42,
    }
    print("BAYES_CFG =", BAYES_CFG)
    print("ğŸ‘‰ Cháº¡y **Cell 5C** Ä‘á»ƒ huáº¥n luyá»‡n & Ä‘Ã¡nh giÃ¡ Bayesian.")

# CELL 5C â€” Huáº¥n luyá»‡n Bayesian Logistic theo BAYES_CFG, Ä‘Ã¡nh giÃ¡ & káº¿t luáº­n

import pymc as pm, arviz as az
import numpy as np, pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

assert "BAYES_CFG" in globals(), "ChÆ°a cÃ³ BAYES_CFG. HÃ£y cháº¡y Cell 5B vÃ  báº¥m 'XÃ¡c nháº­n tham sá»‘'."

with pm.Model() as bayes_logit:
    beta = pm.Normal("beta", mu=0, sigma=BAYES_CFG["prior_sigma_beta"], shape=Xt_train.shape[1])
    intercept = pm.Normal("intercept", mu=0, sigma=BAYES_CFG["prior_sigma_intercept"])
    logits = intercept + pm.math.dot(Xt_train, beta)
    p = pm.math.sigmoid(logits)
    y_obs = pm.Bernoulli("y_obs", p=p, observed=y_train.values)

    idata = pm.sample(
        draws=BAYES_CFG["draws"], tune=BAYES_CFG["tune"],
        target_accept=BAYES_CFG["target_accept"],
        chains=BAYES_CFG["chains"], cores=BAYES_CFG["cores"],
        random_seed=BAYES_CFG["random_seed"],
        progressbar=True
    )

print("âœ… Bayesian model fitted.")
summary = az.summary(idata, var_names=["beta","intercept"], round_to=3)
display(summary.head())

# Posterior mean â†’ dá»± Ä‘oÃ¡n test
beta_mean = idata.posterior["beta"].mean(dim=("chain","draw")).values
intercept_mean = idata.posterior["intercept"].mean(dim=("chain","draw")).values
logits_test = intercept_mean + Xt_test @ beta_mean
proba_bayes = 1/(1+np.exp(-logits_test))
y_pred_bayes = (proba_bayes >= 0.5).astype(int)

# ÄÃ¡nh giÃ¡
acc_b  = accuracy_score(y_test, y_pred_bayes)
prec_b = precision_score(y_test, y_pred_bayes, zero_division=0)
rec_b  = recall_score(y_test, y_pred_bayes, zero_division=0)
f1_b   = f1_score(y_test, y_pred_bayes, zero_division=0)
auc_b  = roc_auc_score(y_test, proba_bayes)

print("\nğŸ“Š ÄÃNH GIÃ (Bayesian Logistic)")
print(f"- Accuracy  : {acc_b:.3f}")
print(f"- Precision : {prec_b:.3f}")
print(f"- Recall    : {rec_b:.3f}")
print(f"- F1-score  : {f1_b:.3f}")
print(f"- ROC AUC   : {auc_b:.3f}")

# Top 5 dÆ°Æ¡ng/Ã¢m theo posterior mean
coef_df_b = pd.DataFrame({"feature": feature_names, "coef": beta_mean})
top_pos_b = coef_df_b.sort_values("coef", ascending=False).head(5)[["feature","coef"]]
top_neg_b = coef_df_b.sort_values("coef", ascending=True).head(5)[["feature","coef"]]

print("\nğŸ“ˆ Top 5 biáº¿n DÆ¯Æ NG (Bayesian):")
display(top_pos_b)
print("\nğŸ“‰ Top 5 biáº¿n Ã‚M (Bayesian):")
display(top_neg_b)

# Káº¿t luáº­n báº±ng lá»i
pos_list = top_pos_b["feature"].tolist()
neg_list = top_neg_b["feature"].tolist()

print("\nğŸ§­ Káº¾T LUáº¬N (Bayesian)")
if selected_threshold is not None:
    print(f"- Target 'Score' ban Ä‘áº§u liÃªn tá»¥c â†’ Ä‘Ã£ chá»n ngÆ°á»¡ng = {selected_threshold:.4f} (classification-oriented balance).")
else:
    print("- Target 'Score' Ä‘Ã£ nhá»‹ phÃ¢n sáºµn, khÃ´ng threshold.")

print(f"- Hiá»‡u suáº¥t: Accuracy={acc_b:.3f}, Precision={prec_b:.3f}, Recall={rec_b:.3f}, F1={f1_b:.3f}, AUC={auc_b:.3f}")
if pos_list: print(f"- Biáº¿n **dÆ°Æ¡ng** (tÄƒng xÃ¡c suáº¥t lá»›p '1'): {', '.join(pos_list)}.")
if neg_list: print(f"- Biáº¿n **Ã¢m** (giáº£m xÃ¡c suáº¥t lá»›p '1'): {', '.join(neg_list)}.")
print("\nğŸ’¡ Æ¯u Ä‘iá»ƒm Bayesian: cÃ³ posterior & credible intervals (xem báº£ng summary) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ má»©c Ä‘á»™ cháº¯c cháº¯n cá»§a tá»«ng biáº¿n.")

# CELL 5D â€” Diá»…n giáº£i Bayesian báº±ng % vÃ  nhÃ³m biáº¿n (cháº¯c cháº¯n dÆ°Æ¡ng/Ã¢m/khÃ´ng xÃ¡c Ä‘á»‹nh)

import numpy as np
import pandas as pd
import arviz as az
from IPython.display import display

# Kiá»ƒm tra dá»¯ liá»‡u cáº§n thiáº¿t
assert "idata" in globals(), "âŒ ChÆ°a cÃ³ 'idata'. HÃ£y cháº¡y Cell 5C trÆ°á»›c."
assert "feature_names" in globals(), "âŒ Thiáº¿u 'feature_names'. HÃ£y cháº¯c Ä‘Ã£ cháº¡y 5A/5C."

# Láº¥y máº«u posterior cá»§a beta: shape (chains, draws, K) â†’ (samples, K)
beta_draws = idata.posterior["beta"].values  # dims: (chain, draw, K)
chains, draws, K = beta_draws.shape
beta_samples = beta_draws.reshape(chains * draws, K)

# TÃ­nh thá»‘ng kÃª cho tá»«ng feature
means = beta_samples.mean(axis=0)
sds   = beta_samples.std(axis=0)
ci_l  = np.quantile(beta_samples, 0.025, axis=0)
ci_u  = np.quantile(beta_samples, 0.975, axis=0)

# XÃ¡c suáº¥t dáº¥u
p_pos = (beta_samples > 0).mean(axis=0)  # P(beta > 0)
p_neg = 1.0 - p_pos

df_bayes = pd.DataFrame({
    "feature": feature_names,
    "mean": means,
    "sd": sds,
    "ci_2.5%": ci_l,
    "ci_97.5%": ci_u,
    "P(beta>0)": p_pos,
    "P(beta<0)": p_neg
})

# PhÃ¢n loáº¡i theo â€œÄ‘á»™ cháº¯c cháº¯nâ€
# - Cháº¯c cháº¯n dÆ°Æ¡ng: CI tháº¥p > 0 hoáº·c P(beta>0) >= 0.975
# - Cháº¯c cháº¯n Ã¢m   : CI cao  < 0 hoáº·c P(beta<0) >= 0.975
# - KhÃ´ng xÃ¡c Ä‘á»‹nh : cÃ²n láº¡i (CI cáº¯t 0), Æ°u tiÃªn P(beta>0) ~ 0.5
certain_pos_mask = (df_bayes["ci_2.5%"] > 0) | (df_bayes["P(beta>0)"] >= 0.975)
certain_neg_mask = (df_bayes["ci_97.5%"] < 0) | (df_bayes["P(beta<0)"] >= 0.975)
uncertain_mask   = ~(certain_pos_mask | certain_neg_mask)

df_bayes["category"] = np.where(
    certain_pos_mask, "certain_positive",
    np.where(certain_neg_mask, "certain_negative", "uncertain")
)

# Sáº¯p xáº¿p Ä‘á»ƒ láº¥y top
# - DÆ°Æ¡ng/Ã‚m: theo |mean| giáº£m dáº§n (tÃ¡c Ä‘á»™ng máº¡nh hÆ¡n)
# - KhÃ´ng xÃ¡c Ä‘á»‹nh: theo |P(beta>0) - 0.5| tÄƒng dáº§n (gáº§n 50% â†’ mÆ¡ há»“ hÆ¡n)
top_pos = (df_bayes[df_bayes["category"] == "certain_positive"]
           .sort_values("mean", ascending=False)
           .head(5))
top_neg = (df_bayes[df_bayes["category"] == "certain_negative"]
           .sort_values("mean", ascending=True)
           .head(5))
uncertain_sorted = (df_bayes[df_bayes["category"] == "uncertain"]
                    .assign(uncert_score=(df_bayes["P(beta>0)"] - 0.5).abs())
                    .sort_values("uncert_score", ascending=True)
                    .head(5))

# Báº£ng pháº§n trÄƒm gá»n gÃ ng
def fmt_pct(x): return f"{x*100:,.1f}%"
view_cols = ["feature", "mean", "sd", "ci_2.5%", "ci_97.5%", "P(beta>0)", "P(beta<0)"]

print("ğŸ“Š Báº¢NG TÃ“M Táº®T POSTERIOR (má»™t pháº§n, top theo |mean|):")
display(df_bayes.reindex(df_bayes["mean"].abs().sort_values(ascending=False).index)
        [view_cols].head(12)
        .assign(**{"P(beta>0)": df_bayes["P(beta>0)"].head(12).map(fmt_pct),
                   "P(beta<0)": df_bayes["P(beta<0)"].head(12).map(fmt_pct)}))

print("\nâœ… Top biáº¿n **cháº¯c cháº¯n DÆ¯Æ NG** (CI95% > 0 hoáº·c P(Î²>0)â‰¥97.5%):")
if len(top_pos):
    display(top_pos[view_cols].assign(**{
        "P(beta>0)": top_pos["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": top_pos["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(khÃ´ng Ä‘á»§ biáº¿n thá»a Ä‘iá»u kiá»‡n)")

print("\nâœ… Top biáº¿n **cháº¯c cháº¯n Ã‚M** (CI95% < 0 hoáº·c P(Î²<0)â‰¥97.5%):")
if len(top_neg):
    display(top_neg[view_cols].assign(**{
        "P(beta>0)": top_neg["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": top_neg["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(khÃ´ng Ä‘á»§ biáº¿n thá»a Ä‘iá»u kiá»‡n)")

print("\nâš–ï¸ Top biáº¿n **KHÃ”NG XÃC Äá»ŠNH** (CI cáº¯t 0, P(Î²>0) gáº§n 50%):")
if len(uncertain_sorted):
    display(uncertain_sorted[view_cols].assign(**{
        "P(beta>0)": uncertain_sorted["P(beta>0)"].map(fmt_pct),
        "P(beta<0)": uncertain_sorted["P(beta<0)"].map(fmt_pct)
    }))
else:
    print("(khÃ´ng Ä‘á»§ biáº¿n thuá»™c nhÃ³m mÆ¡ há»“)")

# Káº¿t luáº­n ngáº¯n gá»n báº±ng lá»i
pos_names = ", ".join(top_pos["feature"].tolist()[:5]) if len(top_pos) else "khÃ´ng cÃ³"
neg_names = ", ".join(top_neg["feature"].tolist()[:5]) if len(top_neg) else "khÃ´ng cÃ³"
unc_names = ", ".join(uncertain_sorted["feature"].tolist()[:5]) if len(uncertain_sorted) else "khÃ´ng cÃ³"

print("\nğŸ§­ Káº¾T LUáº¬N (Bayesian â€“ theo posterior 95% & xÃ¡c suáº¥t dáº¥u)")
if selected_threshold is not None:
    print(f"- Target 'Score' ban Ä‘áº§u liÃªn tá»¥c â†’ ngÆ°á»¡ng = {selected_threshold:.4f} (classification balance).")
else:
    print("- Target 'Score' Ä‘Ã£ nhá»‹ phÃ¢n, khÃ´ng cáº§n threshold.")
print(f"- Biáº¿n **cháº¯c cháº¯n dÆ°Æ¡ng**: {pos_names}.")
print(f"- Biáº¿n **cháº¯c cháº¯n Ã¢m**: {neg_names}.")
print(f"- Biáº¿n **chÆ°a rÃµ (mÆ¡ há»“)**: {unc_names}.")
print("ğŸ’¡ Diá»…n giáº£i: vá»›i biáº¿n cháº¯c cháº¯n dÆ°Æ¡ng/Ã¢m, credible interval 95% khÃ´ng cáº¯t 0 (hoáº·c xÃ¡c suáº¥t dáº¥u â‰¥ 97.5%),\n"
      "cÃ²n nhÃ³m mÆ¡ há»“ cÃ³ xÃ¡c suáº¥t dáº¥u ~50%, cáº§n thÃªm dá»¯ liá»‡u hoáº·c mÃ´ hÃ¬nh khÃ¡c Ä‘á»ƒ kháº³ng Ä‘á»‹nh.")